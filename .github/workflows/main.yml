name: git to gcs
on:
  push:
    path:
    - 'static_data/**'
    branches:
    - main
env:
  workload_identity_provider: projects/95468451293/locations/global/workloadIdentityPools/aky-dev/providers/olist-repo
  service_account: aky-dev@olist-data-engineering.iam.gserviceaccount.com
jobs:
  deploy-to-cloud-storage:
    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    - name: Fetch all git history
      run: |
        git fetch --prune --unshallow
    - name: Check if there are any changes in static_data
      run: |
        if git diff --quiet HEAD~1 HEAD -- static_data/; then
            echo "No changes in static_data, skipping rsync."
          exit 1
          echo "Changes detected in static_data, proceeding with rsync."
        fi
        
    - id: 'auth'
      if: success()
      uses: 'google-github-actions/auth@v2'
      with:
        workload_identity_provider: '${{ env.workload_identity_provider }}'
        service_account: '${{ env.service_account }}'
        project_id: '${{ vars.PROJECT_ID }}'
    - id: 'upload-file'
      uses: 'google-github-actions/upload-cloud-storage@v2'
      with:
        path: '${{ secrets.CSV_PATH }}'
        destination: '${{ secrets.BUCKET_NAME }}'
    - name: Load CSV to BigQuery
      run: |
        for file in static_data/*.csv; do
          filename=$(basename "$file" .csv)
          echo "Uploading $file to BigQuery table $filename..."

          bq load \
            --source_format=CSV \
            --autodetect \
            --replace \
            ${{ secrets.BIGQUERY_DATASET }}.$filename \
            gs://${{ secrets.BUCKET_NAME }}/static_data/$filename.csv

          echo "$file uploaded successfully!"
        done
